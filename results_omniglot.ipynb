{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from omniglot import task_generator\n",
    "from proto_attn_train import train, validate, count_acc\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "import torch_scatter\n",
    "from torch.distributions import Normal\n",
    "import torchvision.datasets\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttrDict(dict):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(AttrDict, self).__init__(*args, **kwargs)\n",
    "        self.__dict__ = self\n",
    "        \n",
    "config = {'dataset': 'omniglot', 'split_name': 'default', 'shot': 5, 'query': 15, 'classes_per_task': [20], 'examples_per_class': 20,\n",
    "          'groups_per_class': 2, 'examples_per_group': 32, 'max_epoch': 10000,\n",
    "          'nb_val_tasks': 1000, 'train_way': 2, 'test_way': 2, 'prob_xor': None, 'beta': 0,\n",
    "          'out_dim': 64, 'iterations': 0, 'temp': 0.5, 'scale': 1, 'verbose': False}\n",
    "config = AttrDict(config)\n",
    "accs = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hot_attn(Q, K, V, temp):\n",
    "    return torch.softmax(Q@K.T/(temp),-1)@V  # * np.sqrt(K.shape[-1])\n",
    "\n",
    "def euclidean_metric(a, b):\n",
    "    n = a.shape[0]\n",
    "    m = b.shape[0]\n",
    "    a = a.unsqueeze(1).expand(n, m, -1)\n",
    "    b = b.unsqueeze(0).expand(n, m, -1)\n",
    "    logits = -((a - b)**2).sum(dim=2)\n",
    "    return logits\n",
    "\n",
    "def z_norm(x, h=1e-7):\n",
    "    return (x - x.mean(0))/(x.std(0, unbiased=True) + h)\n",
    "\n",
    "def conv_block(in_channels, out_channels):\n",
    "    # bn = CustomBatchNorm()\n",
    "    bn = nn.BatchNorm2d(out_channels, momentum=0.01, track_running_stats = False)\n",
    "    # nn.init.uniform_(bn.weight) # for pytorch 1.2 or later\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        bn,\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2)\n",
    "    )\n",
    "\n",
    "class Convnet(nn.Module):\n",
    "    def __init__(self, x_dim=3, hid_dim=64, z_dim=64):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            conv_block(x_dim, hid_dim),\n",
    "            conv_block(hid_dim, hid_dim),\n",
    "            conv_block(hid_dim, hid_dim),\n",
    "            conv_block(hid_dim, hid_dim),\n",
    "        )\n",
    "        self.embeddings = nn.Linear(hid_dim, z_dim)\n",
    "        self.mean = nn.Linear(z_dim, z_dim)\n",
    "        self.logvar = nn.Linear(z_dim, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        h = x.view(x.size(0), -1)\n",
    "        h = self.embeddings(h)\n",
    "        h = nn.ReLU()(h)\n",
    "        mean = self.mean(h)\n",
    "        logvar = self.logvar(h)\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        return Normal(mean, std)\n",
    "    \n",
    "def cos_attn(Q,K,V):\n",
    "    cos = (Q @ K.T) / torch.outer(torch.norm(Q,dim=1),torch.norm(K,dim=1))\n",
    "    return torch.softmax(cos,-1) @ V\n",
    "\n",
    "def mean_abs_dev(X):\n",
    "    return (X-X.mean(0)).abs().mean(0)\n",
    "\n",
    "class feature_selector(torch.nn.Module):\n",
    "    def __init__(self, iterations, temperature, mad=False):\n",
    "        super(feature_selector,self).__init__()\n",
    "        self.iterations = iterations\n",
    "        self.temperature = temperature\n",
    "        self.mad = mad\n",
    "        \n",
    "    def forward(self,X,y):\n",
    "        S = (X-X.mean(0))/(X.std(0) + 0.1)\n",
    "        \n",
    "        for k in y.unique():\n",
    "            for _ in range(self.iterations):\n",
    "                S[y==k] = cos_attn(S[y==k],S[y==k],S[y==k])\n",
    "#                 S[y==k] = hot_attn(S[y==k],S[y==k],S[y==k],self.temperature)\n",
    "        \n",
    "        if self.mad:\n",
    "            return mean_abs_dev(S)\n",
    "        else:\n",
    "            return S.std(0)\n",
    "        \n",
    "its, temp = 5, 64\n",
    "fs = feature_selector(iterations=its, temperature=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_norm(x, h=1e-7):\n",
    "    return (x - x.mean(0))/(x.std(0, unbiased=True) + h)\n",
    "\n",
    "def forward_euclid(train, test, train_labels, config, attn_fn=hot_attn):\n",
    "    iterations=config.iterations\n",
    "    temp=config.temp\n",
    "    scale=config.scale\n",
    "    train, test = z_norm(train), z_norm(test)\n",
    "    \n",
    "    num_classes = train_labels.max() + 1\n",
    "    \n",
    "    # Self-attention feature selection\n",
    "    for _ in range(iterations):\n",
    "        for c in range(num_classes):\n",
    "            t = train[train_labels==c]\n",
    "            train[train_labels==c] = hot_attn(t, t, t, temp)  \n",
    "    rescale = train.abs().mean(0)\n",
    "    rescale = scale * (rescale - rescale.min()) / (rescale.max() - rescale.min() + 1e-7)\n",
    "    \n",
    "    # Compute predictions and accuracy\n",
    "    distances = euclidean_metric(rescale*test, rescale*train)  # Shape=(nb_test, nb_train)\n",
    "    weights = torch.softmax(distances, axis=-1) # Shape=(nb_test, nb_train)\n",
    "    predictions = weights @ F.one_hot(train_labels, num_classes=train_labels.max()+1).float()\n",
    "    predictions = torch.clip(predictions, 0.01, 0.99)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protonets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_proto(train, test, train_labels, **kwargs):\n",
    "    proto = torch_scatter.scatter_mean(train, train_labels.type(torch.int64), dim=0)\n",
    "\n",
    "    # Compute predictions and accuracy\n",
    "    logits = euclidean_metric(test, proto)\n",
    "    # predictions = torch.softmax(logits, axis=-1)\n",
    "    # return predictions\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124416"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  Convnet(x_dim=1)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "epoch 100, loss=2.2504, kl=0.0000, acc=0.6212\n",
      "epoch 200, loss=1.2627, kl=0.0000, acc=0.7672\n",
      "epoch 300, loss=0.9046, kl=0.0000, acc=0.8251\n",
      "epoch 400, loss=0.7205, kl=0.0000, acc=0.8558\n",
      "epoch 500, loss=0.6028, kl=0.0000, acc=0.8764\n",
      "epoch 600, loss=0.5217, kl=0.0000, acc=0.8910\n",
      "epoch 700, loss=0.4622, kl=0.0000, acc=0.9018\n",
      "epoch 800, loss=0.4155, kl=0.0000, acc=0.9105\n",
      "epoch 900, loss=0.3793, kl=0.0000, acc=0.9172\n",
      "epoch 1000, loss=0.3497, kl=0.0000, acc=0.9229\n",
      "epoch 1100, loss=0.3255, kl=0.0000, acc=0.9276\n",
      "epoch 1200, loss=0.3052, kl=0.0000, acc=0.9315\n",
      "epoch 1300, loss=0.2876, kl=0.0000, acc=0.9349\n",
      "epoch 1400, loss=0.2721, kl=0.0000, acc=0.9379\n",
      "epoch 1500, loss=0.2589, kl=0.0000, acc=0.9404\n",
      "epoch 1600, loss=0.2465, kl=0.0000, acc=0.9430\n",
      "epoch 1700, loss=0.2360, kl=0.0000, acc=0.9450\n",
      "epoch 1800, loss=0.2267, kl=0.0000, acc=0.9470\n",
      "epoch 1900, loss=0.2181, kl=0.0000, acc=0.9487\n",
      "epoch 2000, loss=0.2099, kl=0.0000, acc=0.9505\n",
      "epoch 2100, loss=0.2028, kl=0.0000, acc=0.9519\n",
      "epoch 2200, loss=0.1961, kl=0.0000, acc=0.9533\n",
      "epoch 2300, loss=0.1899, kl=0.0000, acc=0.9547\n",
      "epoch 2400, loss=0.1845, kl=0.0000, acc=0.9558\n",
      "epoch 2500, loss=0.1793, kl=0.0000, acc=0.9568\n",
      "epoch 2600, loss=0.1744, kl=0.0000, acc=0.9578\n",
      "epoch 2700, loss=0.1700, kl=0.0000, acc=0.9588\n",
      "epoch 2800, loss=0.1660, kl=0.0000, acc=0.9596\n",
      "epoch 2900, loss=0.1619, kl=0.0000, acc=0.9605\n",
      "epoch 3000, loss=0.1582, kl=0.0000, acc=0.9613\n",
      "epoch 3100, loss=0.1547, kl=0.0000, acc=0.9620\n",
      "epoch 3200, loss=0.1513, kl=0.0000, acc=0.9627\n",
      "epoch 3300, loss=0.1483, kl=0.0000, acc=0.9633\n",
      "epoch 3400, loss=0.1453, kl=0.0000, acc=0.9639\n",
      "epoch 3500, loss=0.1424, kl=0.0000, acc=0.9646\n",
      "epoch 3600, loss=0.1396, kl=0.0000, acc=0.9652\n",
      "epoch 3700, loss=0.1372, kl=0.0000, acc=0.9657\n",
      "epoch 3800, loss=0.1346, kl=0.0000, acc=0.9663\n",
      "epoch 3900, loss=0.1324, kl=0.0000, acc=0.9667\n",
      "epoch 4000, loss=0.1302, kl=0.0000, acc=0.9672\n",
      "epoch 4100, loss=0.1279, kl=0.0000, acc=0.9677\n",
      "epoch 4200, loss=0.1260, kl=0.0000, acc=0.9681\n",
      "epoch 4300, loss=0.1241, kl=0.0000, acc=0.9685\n",
      "epoch 4400, loss=0.1222, kl=0.0000, acc=0.9689\n",
      "epoch 4500, loss=0.1204, kl=0.0000, acc=0.9693\n",
      "epoch 4600, loss=0.1188, kl=0.0000, acc=0.9697\n",
      "epoch 4700, loss=0.1171, kl=0.0000, acc=0.9700\n",
      "epoch 4800, loss=0.1154, kl=0.0000, acc=0.9704\n",
      "epoch 4900, loss=0.1138, kl=0.0000, acc=0.9708\n",
      "epoch 5000, loss=0.1124, kl=0.0000, acc=0.9711\n",
      "epoch 5100, loss=0.1110, kl=0.0000, acc=0.9714\n",
      "epoch 5200, loss=0.1097, kl=0.0000, acc=0.9716\n",
      "epoch 5300, loss=0.1083, kl=0.0000, acc=0.9719\n",
      "epoch 5400, loss=0.1070, kl=0.0000, acc=0.9722\n",
      "epoch 5500, loss=0.1057, kl=0.0000, acc=0.9725\n",
      "epoch 5600, loss=0.1044, kl=0.0000, acc=0.9728\n",
      "epoch 5700, loss=0.1032, kl=0.0000, acc=0.9731\n",
      "epoch 5800, loss=0.1021, kl=0.0000, acc=0.9734\n",
      "epoch 5900, loss=0.1010, kl=0.0000, acc=0.9736\n",
      "epoch 6000, loss=0.1000, kl=0.0000, acc=0.9738\n",
      "epoch 6100, loss=0.0990, kl=0.0000, acc=0.9741\n",
      "epoch 6200, loss=0.0980, kl=0.0000, acc=0.9743\n",
      "epoch 6300, loss=0.0970, kl=0.0000, acc=0.9745\n",
      "epoch 6400, loss=0.0960, kl=0.0000, acc=0.9747\n",
      "epoch 6500, loss=0.0951, kl=0.0000, acc=0.9749\n",
      "epoch 6600, loss=0.0942, kl=0.0000, acc=0.9751\n",
      "epoch 6700, loss=0.0933, kl=0.0000, acc=0.9753\n",
      "epoch 6800, loss=0.0925, kl=0.0000, acc=0.9755\n",
      "epoch 6900, loss=0.0916, kl=0.0000, acc=0.9757\n",
      "epoch 7000, loss=0.0909, kl=0.0000, acc=0.9759\n",
      "epoch 7100, loss=0.0901, kl=0.0000, acc=0.9760\n",
      "epoch 7200, loss=0.0893, kl=0.0000, acc=0.9762\n",
      "epoch 7300, loss=0.0885, kl=0.0000, acc=0.9764\n",
      "epoch 7400, loss=0.0878, kl=0.0000, acc=0.9765\n",
      "epoch 7500, loss=0.0871, kl=0.0000, acc=0.9767\n",
      "epoch 7600, loss=0.0863, kl=0.0000, acc=0.9769\n",
      "epoch 7700, loss=0.0856, kl=0.0000, acc=0.9770\n",
      "epoch 7800, loss=0.0850, kl=0.0000, acc=0.9772\n",
      "epoch 7900, loss=0.0843, kl=0.0000, acc=0.9773\n",
      "epoch 8000, loss=0.0837, kl=0.0000, acc=0.9775\n",
      "epoch 8100, loss=0.0830, kl=0.0000, acc=0.9776\n",
      "epoch 8200, loss=0.0824, kl=0.0000, acc=0.9778\n",
      "epoch 8300, loss=0.0818, kl=0.0000, acc=0.9779\n",
      "epoch 8400, loss=0.0813, kl=0.0000, acc=0.9780\n",
      "epoch 8500, loss=0.0807, kl=0.0000, acc=0.9782\n",
      "epoch 8600, loss=0.0801, kl=0.0000, acc=0.9783\n",
      "epoch 8700, loss=0.0796, kl=0.0000, acc=0.9784\n",
      "epoch 8800, loss=0.0791, kl=0.0000, acc=0.9785\n",
      "epoch 8900, loss=0.0785, kl=0.0000, acc=0.9786\n",
      "epoch 9000, loss=0.0780, kl=0.0000, acc=0.9787\n",
      "epoch 9100, loss=0.0775, kl=0.0000, acc=0.9789\n",
      "epoch 9200, loss=0.0770, kl=0.0000, acc=0.9790\n",
      "epoch 9300, loss=0.0765, kl=0.0000, acc=0.9791\n",
      "epoch 9400, loss=0.0760, kl=0.0000, acc=0.9792\n",
      "epoch 9500, loss=0.0755, kl=0.0000, acc=0.9793\n",
      "epoch 9600, loss=0.0750, kl=0.0000, acc=0.9794\n",
      "epoch 9700, loss=0.0746, kl=0.0000, acc=0.9795\n",
      "epoch 9800, loss=0.0741, kl=0.0000, acc=0.9797\n",
      "epoch 9900, loss=0.0736, kl=0.0000, acc=0.9797\n",
      "epoch 10000, loss=0.0732, kl=0.0000, acc=0.9798\n"
     ]
    }
   ],
   "source": [
    "config.verbose = True\n",
    "model =  Convnet(x_dim=1)\n",
    "model, g = train(task_generator=task_generator,\n",
    "                 model=model,\n",
    "                 forward_fn=classify_proto,\n",
    "                 config=config,\n",
    "                 loss_fn=nn.CrossEntropyLoss()  # F.cross_entropy\n",
    "                )\n",
    "torch.save(model.state_dict(), '/local/scratch/USER/poly_models/proto_omniglot_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "accs_proto, losses_proto = validate(task_generator=task_generator,\n",
    "                        forward_fn=classify_proto,\n",
    "                        config=config,\n",
    "                        model=model,\n",
    "                        loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9855400081276894, 0.014472103031131597)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs_proto), np.std(accs_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "config.iterations = 0\n",
    "accs_attn_test, losses_attn_test = validate(task_generator=task_generator,\n",
    "                        forward_fn=forward_euclid,\n",
    "                        config=config,\n",
    "                        model=model,\n",
    "                        loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9816266762018204, 0.014782069532884237)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs_attn_test), np.std(accs_attn_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_knn(X_S, X_Q, y_spt, config):\n",
    "    logits = euclidean_metric(X_Q, X_S)\n",
    "    closest_idxs = torch.argmax(logits, dim=-1)\n",
    "    return F.one_hot(y_spt[closest_idxs]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  Convnet(x_dim=1)\n",
    "model.load_state_dict(torch.load('/local/scratch/USER/poly_models/proto_omniglot_10k'))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(task_generator, forward_fn, config, model=None, xor_task=None, loss_fn=None):\n",
    "    # Prepare data\n",
    "    g = task_generator(config=config)\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    # Validate\n",
    "    model.eval()\n",
    "    accs = []\n",
    "    losses = []\n",
    "    if loss_fn is None:\n",
    "        loss_fn = nn.BCELoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(config.nb_val_tasks):\n",
    "            # Get and reshape data\n",
    "            data_shot, label_shot, data_query, label_query = g.get_shot_query(config, device, validation=True, xor_task=xor_task, prob_xor=config.prob_xor)\n",
    "\n",
    "            # Compute predictions\n",
    "            data = torch.cat((data_shot, data_query), 0)\n",
    "            embeddings_dist = model(data)\n",
    "            embeddings = embeddings_dist.rsample()\n",
    "            data_shot = embeddings[:data_shot.shape[0]]\n",
    "            data_query = embeddings[data_shot.shape[0]:]\n",
    "            probs = forward_fn(data_shot, data_query, label_shot, config=config)\n",
    "\n",
    "            # Compute distances and loss\n",
    "            loss = loss_fn(probs, label_query)  # F.cross_entropy(logits, label_query)\n",
    "            acc = count_acc(probs, label_query)\n",
    "            losses.append(loss)\n",
    "            accs.append(acc)\n",
    "\n",
    "    return accs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "accs_nn, _ = validate(task_generator=task_generator,\n",
    "                        forward_fn=classify_knn,\n",
    "                        config=config,\n",
    "                        model=model,\n",
    "                        loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9833333420157433, 0.04569221392132561)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs_nn), 100 * np.std(accs_nn)/np.sqrt(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "accs_nn_a, _ = validate(task_generator=alphabet_generator,\n",
    "                        forward_fn=classify_knn,\n",
    "                        config=config,\n",
    "                        model=model,\n",
    "                        loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9576390553116798, 0.2560505383192596)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs_nn_a), 100 * np.std(accs_nn_a)/np.sqrt(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FS+NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_fs_nn(X_S, X_Q, y_spt, config):\n",
    "    train, test = z_norm(X_S), z_norm(X_Q)\n",
    "    train_labels = y_spt\n",
    "    num_classes = train_labels.max() + 1\n",
    "    \n",
    "    # Self-attention feature selection\n",
    "    rescale = (fs(X_S,y_spt))**0.5\n",
    "    \n",
    "    logits = euclidean_metric(rescale*X_Q, rescale*X_S)\n",
    "    closest_idxs = torch.argmax(logits, dim=-1)\n",
    "    return F.one_hot(y_spt[closest_idxs]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "accs_nn, _ = validate(task_generator=task_generator,\n",
    "                        forward_fn=classify_fs_nn,\n",
    "                        config=config,\n",
    "                        model=model,\n",
    "                        loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9832700091004372, 0.04424005643513599)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs_nn), 100 * np.std(accs_nn)/np.sqrt(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "accs_nn_a, _ = validate(task_generator=alphabet_generator,\n",
    "                        forward_fn=classify_fs_nn,\n",
    "                        config=config,\n",
    "                        model=model,\n",
    "                        loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9603964519500733, 0.2411575397687104)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs_nn_a), 100 * np.std(accs_nn_a)/np.sqrt(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_mn(X_S, X_Q, y_spt, config): \n",
    "    mn_cos = (X_Q @ X_S.T) / torch.outer(torch.norm(X_Q,dim=1),torch.norm(X_S,dim=1))\n",
    "    return F.softmax(mn_cos,-1) @ F.one_hot(y_spt).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-3f686216a6d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m accs_mn, _ = validate(task_generator=task_generator,\n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0mforward_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassify_fs_mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         loss_fn=nn.CrossEntropyLoss())\n",
      "\u001b[0;32m<ipython-input-21-8eb73b0e49c1>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(task_generator, forward_fn, config, model, xor_task, loss_fn)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxor_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/auto/homes/USER/prototypical-network-pytorch/omniglot.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config, train, download, root)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;31m# check for what's in the config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/auto/homes/USER/prototypical-network-pytorch/omniglot.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(name, train, download, root)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# regularOmniglot is a wrapper for the torchvision Omniglot dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m#  that behaves more typically than\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         return regularOmniglot(root=root,\n\u001b[0m\u001b[1;32m     62\u001b[0m                                \u001b[0mbackground\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                                download=download)\n",
      "\u001b[0;32m/auto/homes/USER/prototypical-network-pytorch/omniglot.py\u000b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, download, background)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m270\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m                 \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m964\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m964\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch38/lib/python3.8/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accs_mn, _ = validate(task_generator=task_generator,\n",
    "                        forward_fn=classify_mn,\n",
    "                        config=config,\n",
    "                        model=model,\n",
    "                        loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(accs_mn), 100 * np.std(accs_mn)/np.sqrt(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "accs_mn_a, _ = validate(task_generator=alphabet_generator,\n",
    "                        forward_fn=classify_mn,\n",
    "                        config=config,\n",
    "                        model=model,\n",
    "                        loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8135404341518879, 0.267796556178745)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs_mn_a), 100 * np.std(accs_mn_a)/np.sqrt(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FS+MN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_fs_mn(X_S, X_Q, y_spt, config):\n",
    "    # Self-attention feature selection\n",
    "    rescale = (fs(X_S,y_spt))**0.5\n",
    "    X_Q = X_Q*rescale\n",
    "    X_S = X_S*rescale\n",
    "    \n",
    "    mn_cos = (X_Q @ X_S.T) / torch.outer(torch.norm(X_Q,dim=1),torch.norm(X_S,dim=1))\n",
    "    return F.softmax(mn_cos,-1) @ F.one_hot(y_spt).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "accs_mn, _ = validate(task_generator=task_generator,\n",
    "                        forward_fn=classify_fs_mn,\n",
    "                        config=config,\n",
    "                        model=model,\n",
    "                        loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9792233422994614, 0.04986060735065735)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs_mn), 100 * np.std(accs_mn)/np.sqrt(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "accs_mn_a, _ = validate(task_generator=alphabet_generator,\n",
    "                        forward_fn=classify_fs_mn,\n",
    "                        config=config,\n",
    "                        model=model,\n",
    "                        loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8144082833528519, 0.2872890591383413)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs_mn_a), 100 * np.std(accs_mn_a)/np.sqrt(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection + euclid attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "epoch 100, loss=2.7803, kl=0.0000, acc=0.3025\n",
      "epoch 200, loss=2.6343, kl=0.0000, acc=0.4568\n",
      "epoch 300, loss=2.5462, kl=0.0000, acc=0.5473\n",
      "epoch 400, loss=2.4917, kl=0.0000, acc=0.6032\n",
      "epoch 500, loss=2.4519, kl=0.0000, acc=0.6435\n",
      "epoch 600, loss=2.4229, kl=0.0000, acc=0.6729\n",
      "epoch 700, loss=2.4004, kl=0.0000, acc=0.6958\n",
      "epoch 800, loss=2.3816, kl=0.0000, acc=0.7149\n",
      "epoch 900, loss=2.3666, kl=0.0000, acc=0.7301\n",
      "epoch 1000, loss=2.3534, kl=0.0000, acc=0.7434\n",
      "epoch 1100, loss=2.3406, kl=0.0000, acc=0.7563\n",
      "epoch 1200, loss=2.3294, kl=0.0000, acc=0.7676\n",
      "epoch 1300, loss=2.3199, kl=0.0000, acc=0.7773\n",
      "epoch 1400, loss=2.3113, kl=0.0000, acc=0.7859\n",
      "epoch 1500, loss=2.3042, kl=0.0000, acc=0.7930\n",
      "epoch 1600, loss=2.2975, kl=0.0000, acc=0.7997\n",
      "epoch 1700, loss=2.2931, kl=0.0000, acc=0.8041\n",
      "epoch 1800, loss=2.2883, kl=0.0000, acc=0.8090\n",
      "epoch 1900, loss=2.2838, kl=0.0000, acc=0.8134\n",
      "epoch 2000, loss=2.2794, kl=0.0000, acc=0.8179\n",
      "epoch 2100, loss=2.2748, kl=0.0000, acc=0.8225\n",
      "epoch 2200, loss=2.2708, kl=0.0000, acc=0.8266\n",
      "epoch 2300, loss=2.2670, kl=0.0000, acc=0.8304\n",
      "epoch 2400, loss=2.2631, kl=0.0000, acc=0.8343\n",
      "epoch 2500, loss=2.2597, kl=0.0000, acc=0.8377\n",
      "epoch 2600, loss=2.2564, kl=0.0000, acc=0.8410\n",
      "epoch 2700, loss=2.2538, kl=0.0000, acc=0.8436\n",
      "epoch 2800, loss=2.2507, kl=0.0000, acc=0.8467\n",
      "epoch 2900, loss=2.2478, kl=0.0000, acc=0.8496\n",
      "epoch 3000, loss=2.2451, kl=0.0000, acc=0.8523\n",
      "epoch 3100, loss=2.2425, kl=0.0000, acc=0.8550\n",
      "epoch 3200, loss=2.2402, kl=0.0000, acc=0.8573\n",
      "epoch 3300, loss=2.2378, kl=0.0000, acc=0.8597\n",
      "epoch 3400, loss=2.2356, kl=0.0000, acc=0.8619\n",
      "epoch 3500, loss=2.2334, kl=0.0000, acc=0.8641\n",
      "epoch 3600, loss=2.2313, kl=0.0000, acc=0.8662\n",
      "epoch 3700, loss=2.2294, kl=0.0000, acc=0.8680\n",
      "epoch 3800, loss=2.2275, kl=0.0000, acc=0.8700\n",
      "epoch 3900, loss=2.2258, kl=0.0000, acc=0.8717\n",
      "epoch 4000, loss=2.2241, kl=0.0000, acc=0.8734\n",
      "epoch 4100, loss=2.2225, kl=0.0000, acc=0.8750\n",
      "epoch 4200, loss=2.2211, kl=0.0000, acc=0.8764\n",
      "epoch 4300, loss=2.2197, kl=0.0000, acc=0.8778\n",
      "epoch 4400, loss=2.2182, kl=0.0000, acc=0.8793\n",
      "epoch 4500, loss=2.2168, kl=0.0000, acc=0.8808\n",
      "epoch 4600, loss=2.2152, kl=0.0000, acc=0.8824\n",
      "epoch 4700, loss=2.2139, kl=0.0000, acc=0.8836\n",
      "epoch 4800, loss=2.2127, kl=0.0000, acc=0.8849\n",
      "epoch 4900, loss=2.2113, kl=0.0000, acc=0.8863\n",
      "epoch 5000, loss=2.2102, kl=0.0000, acc=0.8873\n",
      "epoch 5100, loss=2.2094, kl=0.0000, acc=0.8881\n",
      "epoch 5200, loss=2.2083, kl=0.0000, acc=0.8892\n",
      "epoch 5300, loss=2.2071, kl=0.0000, acc=0.8904\n",
      "epoch 5400, loss=2.2060, kl=0.0000, acc=0.8915\n",
      "epoch 5500, loss=2.2048, kl=0.0000, acc=0.8927\n",
      "epoch 5600, loss=2.2037, kl=0.0000, acc=0.8938\n",
      "epoch 5700, loss=2.2025, kl=0.0000, acc=0.8950\n",
      "epoch 6400, loss=2.1964, kl=0.0000, acc=0.9011\n",
      "epoch 6500, loss=2.1958, kl=0.0000, acc=0.9017\n",
      "epoch 6600, loss=2.1950, kl=0.0000, acc=0.9024\n",
      "epoch 6700, loss=2.1944, kl=0.0000, acc=0.9030\n",
      "epoch 6800, loss=2.1937, kl=0.0000, acc=0.9037\n",
      "epoch 6900, loss=2.1930, kl=0.0000, acc=0.9044\n",
      "epoch 7000, loss=2.1923, kl=0.0000, acc=0.9051\n",
      "epoch 7100, loss=2.1917, kl=0.0000, acc=0.9057\n",
      "epoch 7200, loss=2.1910, kl=0.0000, acc=0.9064\n",
      "epoch 7300, loss=2.1903, kl=0.0000, acc=0.9071\n",
      "epoch 7400, loss=2.1897, kl=0.0000, acc=0.9077\n",
      "epoch 7500, loss=2.1891, kl=0.0000, acc=0.9083\n",
      "epoch 7600, loss=2.1884, kl=0.0000, acc=0.9090\n",
      "epoch 7700, loss=2.1879, kl=0.0000, acc=0.9095\n",
      "epoch 7800, loss=2.1873, kl=0.0000, acc=0.9101\n",
      "epoch 7900, loss=2.1869, kl=0.0000, acc=0.9105\n",
      "epoch 8000, loss=2.1863, kl=0.0000, acc=0.9110\n",
      "epoch 8100, loss=2.1859, kl=0.0000, acc=0.9114\n",
      "epoch 8200, loss=2.1854, kl=0.0000, acc=0.9120\n",
      "epoch 8300, loss=2.1848, kl=0.0000, acc=0.9125\n",
      "epoch 8400, loss=2.1843, kl=0.0000, acc=0.9130\n",
      "epoch 8500, loss=2.1839, kl=0.0000, acc=0.9135\n",
      "epoch 8600, loss=2.1833, kl=0.0000, acc=0.9141\n",
      "epoch 8700, loss=2.1827, kl=0.0000, acc=0.9146\n",
      "epoch 8800, loss=2.1822, kl=0.0000, acc=0.9151\n",
      "epoch 8900, loss=2.1817, kl=0.0000, acc=0.9156\n",
      "epoch 9000, loss=2.1812, kl=0.0000, acc=0.9161\n",
      "epoch 9100, loss=2.1807, kl=0.0000, acc=0.9166\n",
      "epoch 9200, loss=2.1804, kl=0.0000, acc=0.9169\n",
      "epoch 9300, loss=2.1800, kl=0.0000, acc=0.9173\n",
      "epoch 9400, loss=2.1795, kl=0.0000, acc=0.9178\n",
      "epoch 9500, loss=2.1791, kl=0.0000, acc=0.9182\n",
      "epoch 9600, loss=2.1786, kl=0.0000, acc=0.9187\n",
      "epoch 9700, loss=2.1781, kl=0.0000, acc=0.9192\n",
      "epoch 9800, loss=2.1776, kl=0.0000, acc=0.9197\n",
      "epoch 9900, loss=2.1771, kl=0.0000, acc=0.9201\n",
      "epoch 10000, loss=2.1767, kl=0.0000, acc=0.9206\n"
     ]
    }
   ],
   "source": [
    "config.verbose = True\n",
    "model =  Convnet(x_dim=1)\n",
    "model, g = train(task_generator=task_generator,\n",
    "                 model=model,\n",
    "                 forward_fn=forward_euclid,\n",
    "                 config=config,\n",
    "                 loss_fn=F.cross_entropy)\n",
    "torch.save(model.state_dict(), '/local/scratch/USER/poly_models/attn_omniglot_10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9594400005936623"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs, losses = validate(task_generator=task_generator,\n",
    "                    forward_fn=forward_euclid,\n",
    "                    config=config,\n",
    "                    model=model,\n",
    "                    loss_fn=F.cross_entropy)\n",
    "np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model =  Convnet(x_dim=1)\n",
    "model.load_state_dict(torch.load('/local/scratch/USER/poly_models/attn_omniglot_10k'))\n",
    "model = model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9624566689729691, 0.06424073820264695)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs, losses = validate(task_generator=task_generator,\n",
    "                    forward_fn=forward_euclid,\n",
    "                    config=config,\n",
    "                    model=model,\n",
    "                    loss_fn=F.cross_entropy)\n",
    "np.mean(accs), 100 * np.std(accs)/np.sqrt(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test performance on alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class alphabetOmniglot(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A (possibly dumb) way to wrap the base Omniglot dataset to get it to\n",
    "    behave like the rest of the pytorch datasets, i.e. having the data\n",
    "    and targets being attributes such that\n",
    "        dataset.data[i] is the i-th data\n",
    "        dataset.targets[i] is the i-th target\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        root,\n",
    "        download,\n",
    "        background,\n",
    "    ):\n",
    "        base = torchvision.datasets.Omniglot(root=root,\n",
    "                                             download=download,\n",
    "                                             background=background)\n",
    "        \n",
    "        transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize((28,28)),\n",
    "            torchvision.transforms.ToTensor()\n",
    "        ])\n",
    "        data, targets = [], []\n",
    "        for ex in base:\n",
    "            data.append(transform(ex[0]))\n",
    "        self.data = torch.cat(data, 0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.data[idx]\n",
    "    \n",
    "class alphabet_generator:\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        dataset = alphabetOmniglot(root='./data/',download=True,background=False)\n",
    "        test = torchvision.datasets.Omniglot(root='/home/USER/marionette/data/',\n",
    "                                             download=True,\n",
    "                                             background=False)\n",
    "        self.dataset = dataset\n",
    "        self.test = test\n",
    "        \n",
    "        # get character indices\n",
    "        indices = []\n",
    "        for alphabet in test._alphabets:\n",
    "            alphabet_index = []\n",
    "            for idx,character in enumerate(test._characters):\n",
    "                if character.startswith(alphabet):\n",
    "                    alphabet_index.append(idx)\n",
    "            indices.append(alphabet_index)\n",
    "        self.indices = indices\n",
    "    \n",
    "    def get_shot_query(self, config, device, **task_kwargs):\n",
    "        # select n alphabets, m characters, s support from each character and the rest are queries (20-s)\n",
    "        n, m, s = 3, 13, 7\n",
    "        \n",
    "        # choose alphabets\n",
    "        dataset = self.dataset\n",
    "        indices = self.indices\n",
    "        alphabets = np.random.choice(len(indices),n)\n",
    "        support_ids = []\n",
    "        query_ids = []\n",
    "        support_labels = []\n",
    "        query_labels = []\n",
    "        for label,a in enumerate(alphabets):\n",
    "            # permute to get random sample of characters\n",
    "            characters = np.random.permutation(indices[a])[:m]\n",
    "            for c in characters:\n",
    "                # there are 20 of each character, with dataset ids starting at 20c\n",
    "                shuffled_ids = np.random.permutation(list(range(c*20,(c+1)*20)))\n",
    "                support_ids += list(shuffled_ids[:s])\n",
    "                query_ids += list(shuffled_ids[s:])\n",
    "            support_labels += [label]*m*s\n",
    "            query_labels += [label]*m*(20-s)\n",
    "        support_labels, query_labels = torch.tensor(support_labels), torch.tensor(query_labels)\n",
    "        support, queries = dataset.data[support_ids][:, None, ...], dataset.data[query_ids][:, None, ...]\n",
    "        \n",
    "        return support.to(device), support_labels.long().to(device), queries.to(device), query_labels.long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-4e2b70daf039>\u001b[0m in
      \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m
      \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/local/scratch/USER/poly_models/proto_omniglot_10k'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/local/scratch/USER/poly_models/proto_omniglot_10k'))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8341558179855346, 0.08456723601631734)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs, losses = validate(task_generator=alphabet_generator,\n",
    "                    forward_fn=classify_proto,\n",
    "                    config=config,\n",
    "                    model=model,\n",
    "                    loss_fn=nn.CrossEntropyLoss())\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.948380671530962, 0.0822310599780685)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs, losses = validate(task_generator=alphabet_generator,\n",
    "                    forward_fn=forward_euclid,\n",
    "                    config=config,\n",
    "                    model=model,\n",
    "                    loss_fn=nn.CrossEntropyLoss())\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9605266293287277, 0.0738353866045988)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.iterations = 0\n",
    "accs, losses = validate(task_generator=alphabet_generator,\n",
    "                    forward_fn=forward_euclid,\n",
    "                    config=config,\n",
    "                    model=model,\n",
    "                    loss_fn=nn.CrossEntropyLoss())\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9423057215809822, 0.26429950746671643)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/local/scratch/USER/poly_models/attn_omniglot_10k'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "accs, losses = validate(task_generator=alphabet_generator,\n",
    "                    forward_fn=forward_euclid,\n",
    "                    config=config,\n",
    "                    model=model,\n",
    "                    loss_fn=F.cross_entropy)\n",
    "np.mean(accs), 100 * np.std(accs)/np.sqrt(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Omniglot unseen character alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class alphabet_generator_2:\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        dataset = alphabetOmniglot(root='./data/',download=True,background=False)\n",
    "        test = torchvision.datasets.Omniglot(root='/home/USER/marionette/data/',\n",
    "                                             download=True,\n",
    "                                             background=False)\n",
    "        self.dataset = dataset\n",
    "        self.test = test\n",
    "        \n",
    "        # get character indices\n",
    "        indices = []\n",
    "        for alphabet in test._alphabets:\n",
    "            alphabet_index = []\n",
    "            for idx,character in enumerate(test._characters):\n",
    "                if character.startswith(alphabet):\n",
    "                    alphabet_index.append(idx)\n",
    "            indices.append(alphabet_index)\n",
    "        self.indices = indices\n",
    "    \n",
    "    def get_shot_query(self, config, device, **task_kwargs):\n",
    "        dataset = self.dataset\n",
    "        indices = self.indices\n",
    "        \n",
    "        # select n alphabets, m characters, s support from each character and the rest are queries (20-s)\n",
    "        n, m, s, x = 3, 13, 10, 10\n",
    "\n",
    "        # choose alphabets\n",
    "        alphabets = np.random.choice(len(indices),n)\n",
    "        support_ids = []\n",
    "        query_ids = []\n",
    "        support_labels = []\n",
    "        query_labels = []\n",
    "        for label,a in enumerate(alphabets):\n",
    "            # permute to get random sample of characters\n",
    "            characters = np.random.permutation(indices[a])[:m]\n",
    "            # first s are support, second (m-s) are query\n",
    "            support_characters = characters[:s]\n",
    "            query_characters = characters[s:]\n",
    "            for sc in support_characters:\n",
    "                # there are 20 of each character, with dataset ids starting at 20c\n",
    "                shuffled_ids = np.random.permutation(list(range(sc*20,(sc+1)*20)))\n",
    "                support_ids += list(shuffled_ids[:x])\n",
    "            for qc in query_characters:\n",
    "                # there are 20 of each character, with dataset ids starting at 20c\n",
    "                shuffled_ids = np.random.permutation(list(range(qc*20,(qc+1)*20)))\n",
    "                query_ids += list(shuffled_ids[:x])\n",
    "            support_labels += [label]*s*x\n",
    "            query_labels += [label]*(m-s)*x\n",
    "        support_labels, query_labels = torch.tensor(support_labels), torch.tensor(query_labels)\n",
    "        support, queries = dataset.data[support_ids][:, None, ...], dataset.data[query_ids][:, None, ...]\n",
    "        \n",
    "        return support.to(device), support_labels.long().to(device), queries.to(device), query_labels.long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model =  Convnet(x_dim=1)\n",
    "model.load_state_dict(torch.load('/local/scratch/USER/poly_models/proto_omniglot_10k'))\n",
    "model = model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.736477778211236, 0.16001268992141998)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs, losses = validate(task_generator=alphabet_generator_2,\n",
    "                    forward_fn=classify_proto,\n",
    "                    config=config,\n",
    "                    model=model,\n",
    "                    loss_fn=nn.CrossEntropyLoss())\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7308333332315088, 0.15965099264112556)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs, losses = validate(task_generator=alphabet_generator_2,\n",
    "                    forward_fn=classify_proto,\n",
    "                    config=config,\n",
    "                    model=model,\n",
    "                    loss_fn=nn.CrossEntropyLoss())\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7180111112445593, 0.16872921640078636)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.iterations = 0\n",
    "accs, losses = validate(task_generator=alphabet_generator_2,\n",
    "                    forward_fn=forward_euclid,\n",
    "                    config=config,\n",
    "                    model=model,\n",
    "                    loss_fn=nn.CrossEntropyLoss())\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.704088889632374, 0.16819248251491278)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.iterations = 2\n",
    "accs, losses = validate(task_generator=alphabet_generator_2,\n",
    "                    forward_fn=forward_euclid,\n",
    "                    config=config,\n",
    "                    model=model,\n",
    "                    loss_fn=nn.CrossEntropyLoss())\n",
    "np.mean(accs), np.std(accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MAML_utils.meta import Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "g = task_generator(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    epoch = 10000\n",
    "    n_way = 20\n",
    "    k_spt = 5\n",
    "    k_qry = 15\n",
    "    imgsz = 28\n",
    "    imgc = 1\n",
    "    task_num = 1\n",
    "    meta_lr = 1e-3\n",
    "    update_lr = 0.4\n",
    "    update_step = 5\n",
    "    update_step_test = 10\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta(\n",
      "  (net): Learner(\n",
      "    conv2d:(ch_in:1, ch_out:64, k:3x3, stride:2, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(64,)\n",
      "    conv2d:(ch_in:64, ch_out:64, k:3x3, stride:2, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(64,)\n",
      "    conv2d:(ch_in:64, ch_out:64, k:3x3, stride:2, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(64,)\n",
      "    conv2d:(ch_in:64, ch_out:64, k:2x2, stride:1, padding:0)\n",
      "    relu:(True,)\n",
      "    bn:(64,)\n",
      "    flatten:()\n",
      "    linear:(in:64, out:20)\n",
      "    \n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 64x1x3x3]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 64x64x3x3]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (8): Parameter containing: [torch.FloatTensor of size 64x64x3x3]\n",
      "        (9): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (10): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (11): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (12): Parameter containing: [torch.FloatTensor of size 64x64x2x2]\n",
      "        (13): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (14): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (15): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (16): Parameter containing: [torch.FloatTensor of size 20x64]\n",
      "        (17): Parameter containing: [torch.FloatTensor of size 20]\n",
      "    )\n",
      "    (vars_bn): ParameterList(\n",
      "        (0): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (1): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (2): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (3): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (4): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (5): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (6): Parameter containing: [torch.FloatTensor of size 64]\n",
      "        (7): Parameter containing: [torch.FloatTensor of size 64]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 92756\n",
      "step: 0 \ttraining acc: [0.05666667 0.14       0.23333333 0.26       0.26       0.26333333]\n",
      "Test acc: [0.05   0.2053 0.2961 0.318  0.3254 0.3289 0.3315 0.3335 0.3352 0.3364\n",
      " 0.3374]\n",
      "step: 50 \ttraining acc: [0.07666667 0.48       0.59666667 0.60666667 0.60666667 0.60333333]\n",
      "step: 100 \ttraining acc: [0.07333333 0.48       0.55666667 0.63333333 0.62666667 0.63333333]\n",
      "step: 150 \ttraining acc: [0.03666667 0.36       0.55       0.58333333 0.63333333 0.62666667]\n",
      "step: 200 \ttraining acc: [0.12       0.52       0.63       0.65666667 0.65333333 0.66333333]\n",
      "step: 250 \ttraining acc: [0.04       0.48666667 0.61       0.67666667 0.71       0.73333333]\n",
      "step: 300 \ttraining acc: [0.05666667 0.44333333 0.64       0.67333333 0.67666667 0.68666667]\n",
      "step: 350 \ttraining acc: [0.03333333 0.67666667 0.78333333 0.82       0.81333333 0.83      ]\n",
      "step: 400 \ttraining acc: [0.08       0.45       0.59666667 0.69       0.72333333 0.72666667]\n",
      "step: 450 \ttraining acc: [0.08333333 0.54333333 0.71       0.73666667 0.74666667 0.75333333]\n",
      "step: 500 \ttraining acc: [0.06333333 0.61       0.75666667 0.78333333 0.78666667 0.79666667]\n",
      "Test acc: [0.0493 0.607  0.7427 0.777  0.7896 0.797  0.8013 0.8037 0.8057 0.807\n",
      " 0.808 ]\n",
      "step: 550 \ttraining acc: [0.06333333 0.56       0.76       0.80333333 0.82333333 0.82666667]\n",
      "step: 600 \ttraining acc: [0.03666667 0.63       0.78       0.81333333 0.81666667 0.82666667]\n",
      "step: 650 \ttraining acc: [0.10333333 0.57333333 0.72       0.76666667 0.83       0.84      ]\n",
      "step: 700 \ttraining acc: [0.05666667 0.61       0.72       0.75666667 0.78       0.78333333]\n",
      "step: 750 \ttraining acc: [0.01       0.58333333 0.69666667 0.75666667 0.76       0.75666667]\n",
      "step: 800 \ttraining acc: [0.02       0.77       0.80333333 0.82       0.84666667 0.85      ]\n",
      "step: 850 \ttraining acc: [0.00333333 0.63       0.76666667 0.8        0.80333333 0.82      ]\n",
      "step: 900 \ttraining acc: [0.01       0.55666667 0.8        0.80666667 0.82       0.82333333]\n",
      "step: 950 \ttraining acc: [0.05333333 0.54333333 0.71333333 0.80333333 0.83666667 0.83666667]\n",
      "step: 1000 \ttraining acc: [0.02333333 0.72       0.82333333 0.86       0.86666667 0.87      ]\n",
      "Test acc: [0.0517 0.652  0.776  0.8135 0.8267 0.8335 0.8374 0.84   0.8413 0.843\n",
      " 0.8438]\n",
      "step: 1050 \ttraining acc: [0.05666667 0.62666667 0.77       0.81333333 0.83333333 0.83666667]\n",
      "step: 1100 \ttraining acc: [0.06666667 0.75666667 0.81666667 0.89       0.89666667 0.90333333]\n",
      "step: 1150 \ttraining acc: [0.09       0.66       0.75666667 0.82333333 0.87       0.87666667]\n",
      "step: 1200 \ttraining acc: [0.04666667 0.61666667 0.75666667 0.85       0.86333333 0.87      ]\n",
      "step: 1250 \ttraining acc: [0.04       0.66       0.78333333 0.82666667 0.85       0.84333333]\n",
      "step: 1300 \ttraining acc: [0.01       0.68333333 0.78       0.80666667 0.81       0.81      ]\n",
      "step: 1350 \ttraining acc: [0.01666667 0.62666667 0.71666667 0.76666667 0.76333333 0.76666667]\n",
      "step: 1400 \ttraining acc: [0.10666667 0.59333333 0.7        0.74333333 0.81       0.82333333]\n",
      "step: 1450 \ttraining acc: [0.00333333 0.72       0.87666667 0.88       0.88666667 0.88333333]\n",
      "step: 1500 \ttraining acc: [0.01666667 0.71333333 0.79       0.80666667 0.81666667 0.84      ]\n",
      "Test acc: [0.05032 0.692   0.803   0.8354  0.848   0.8545  0.858   0.8604  0.862\n",
      " 0.863   0.864  ]\n",
      "step: 1550 \ttraining acc: [0.08333333 0.73333333 0.75666667 0.78666667 0.83333333 0.83666667]\n",
      "step: 1600 \ttraining acc: [0.02       0.78333333 0.81666667 0.8        0.82333333 0.81333333]\n",
      "step: 1650 \ttraining acc: [0.1        0.76333333 0.86       0.88       0.88333333 0.88333333]\n",
      "step: 1700 \ttraining acc: [0.05       0.64666667 0.74333333 0.79666667 0.82333333 0.83      ]\n",
      "step: 1750 \ttraining acc: [0.09666667 0.76666667 0.86333333 0.87666667 0.89666667 0.9       ]\n",
      "step: 1800 \ttraining acc: [0.01333333 0.72333333 0.84       0.84666667 0.83666667 0.88333333]\n",
      "step: 1850 \ttraining acc: [0.08       0.81333333 0.91666667 0.92666667 0.93333333 0.93      ]\n",
      "step: 1900 \ttraining acc: [0.06333333 0.70666667 0.84333333 0.86666667 0.83       0.84      ]\n",
      "step: 1950 \ttraining acc: [0.08666667 0.72       0.88333333 0.87666667 0.87666667 0.88666667]\n",
      "step: 2000 \ttraining acc: [0.10333333 0.62333333 0.85333333 0.87       0.88       0.88      ]\n",
      "Test acc: [0.04932 0.738   0.831   0.8555  0.867   0.8726  0.876   0.878   0.8794\n",
      " 0.8804  0.8813 ]\n",
      "step: 2050 \ttraining acc: [0.05666667 0.78       0.85       0.87       0.87666667 0.88333333]\n",
      "step: 2100 \ttraining acc: [0.04       0.74333333 0.85333333 0.87666667 0.88333333 0.89333333]\n",
      "step: 2150 \ttraining acc: [0.06666667 0.79333333 0.87666667 0.88       0.88333333 0.88666667]\n",
      "step: 2200 \ttraining acc: [0.05       0.74       0.83       0.86333333 0.85       0.87      ]\n",
      "step: 2250 \ttraining acc: [0.01333333 0.68666667 0.84333333 0.86333333 0.88       0.90666667]\n",
      "step: 2300 \ttraining acc: [0.1  0.82 0.84 0.89 0.88 0.86]\n",
      "step: 2350 \ttraining acc: [0.02       0.8        0.92666667 0.92666667 0.93       0.93333333]\n",
      "step: 2400 \ttraining acc: [0.02333333 0.58666667 0.8        0.83333333 0.81333333 0.87      ]\n",
      "step: 2450 \ttraining acc: [0.00333333 0.77333333 0.86333333 0.89666667 0.90666667 0.91      ]\n",
      "step: 2500 \ttraining acc: [0.07       0.82       0.9        0.91666667 0.89333333 0.92      ]\n",
      "Test acc: [0.05112 0.789   0.858   0.873   0.8833  0.888   0.891   0.8926  0.8936\n",
      " 0.8945  0.895  ]\n",
      "step: 2550 \ttraining acc: [0.07666667 0.84       0.9        0.9        0.92666667 0.93333333]\n",
      "step: 2600 \ttraining acc: [0.03       0.84       0.93       0.92333333 0.93666667 0.93666667]\n",
      "step: 2650 \ttraining acc: [0.03666667 0.81       0.85333333 0.85333333 0.87666667 0.89333333]\n",
      "step: 2700 \ttraining acc: [0.05333333 0.79666667 0.87666667 0.88       0.88333333 0.89333333]\n",
      "step: 2750 \ttraining acc: [0.08       0.76333333 0.86       0.85666667 0.87       0.87333333]\n",
      "step: 2800 \ttraining acc: [0.02333333 0.76333333 0.84666667 0.87       0.86666667 0.86666667]\n",
      "step: 2850 \ttraining acc: [0.04333333 0.87666667 0.89       0.89333333 0.91666667 0.91666667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2900 \ttraining acc: [0.01       0.76666667 0.87666667 0.87666667 0.88       0.89      ]\n",
      "step: 2950 \ttraining acc: [0.07666667 0.78333333 0.84       0.88333333 0.86333333 0.87333333]\n",
      "step: 3000 \ttraining acc: [0.08333333 0.67333333 0.81333333 0.82333333 0.83333333 0.83666667]\n",
      "Test acc: [0.04935 0.818   0.8794  0.89    0.897   0.9004  0.903   0.9043  0.906\n",
      " 0.9062  0.907  ]\n",
      "step: 3050 \ttraining acc: [0.04333333 0.84       0.86666667 0.88333333 0.89333333 0.89      ]\n",
      "step: 3100 \ttraining acc: [0.04       0.83       0.90666667 0.91       0.91       0.90666667]\n",
      "step: 3150 \ttraining acc: [0.09333333 0.89       0.9        0.93666667 0.94       0.93666667]\n",
      "step: 3200 \ttraining acc: [0.06       0.88       0.92666667 0.94       0.94333333 0.94333333]\n",
      "step: 3250 \ttraining acc: [0.09       0.76666667 0.84       0.85333333 0.86333333 0.87333333]\n",
      "step: 3300 \ttraining acc: [0.01       0.81333333 0.89333333 0.89333333 0.89333333 0.89      ]\n",
      "step: 3350 \ttraining acc: [0.05666667 0.74333333 0.86       0.86666667 0.86333333 0.87      ]\n",
      "step: 3400 \ttraining acc: [0.05333333 0.81666667 0.86       0.87       0.87       0.87666667]\n",
      "step: 3450 \ttraining acc: [0.05       0.86       0.89666667 0.90666667 0.91333333 0.91      ]\n",
      "step: 3500 \ttraining acc: [0.00333333 0.71333333 0.78666667 0.84666667 0.85       0.86      ]\n",
      "Test acc: [0.04993 0.838   0.89    0.9     0.9062  0.9097  0.911   0.9126  0.913\n",
      " 0.914   0.915  ]\n",
      "step: 3550 \ttraining acc: [0.06       0.9        0.94333333 0.93333333 0.94333333 0.96      ]\n",
      "step: 3600 \ttraining acc: [0.02666667 0.84333333 0.90666667 0.91666667 0.92333333 0.92666667]\n",
      "step: 3650 \ttraining acc: [0.05       0.86       0.93666667 0.94       0.94333333 0.94666667]\n",
      "step: 3700 \ttraining acc: [0.00666667 0.86       0.91333333 0.91666667 0.91666667 0.91666667]\n",
      "step: 3750 \ttraining acc: [0.10333333 0.76333333 0.79666667 0.83       0.86333333 0.87666667]\n",
      "step: 3800 \ttraining acc: [0.07666667 0.88       0.89333333 0.89       0.91       0.91      ]\n",
      "step: 3850 \ttraining acc: [0.04333333 0.81333333 0.92666667 0.92333333 0.92666667 0.93      ]\n",
      "step: 3900 \ttraining acc: [0.06666667 0.81666667 0.85666667 0.85333333 0.88       0.88333333]\n",
      "step: 3950 \ttraining acc: [0.05333333 0.73       0.73333333 0.77333333 0.81333333 0.81333333]\n",
      "step: 4000 \ttraining acc: [0.04333333 0.81       0.86333333 0.87666667 0.87666667 0.87666667]\n",
      "Test acc: [0.05148 0.854   0.8975  0.905   0.91    0.913   0.9155  0.9165  0.9175\n",
      " 0.918   0.919  ]\n",
      "step: 4050 \ttraining acc: [0.01333333 0.84       0.82666667 0.85       0.87666667 0.9       ]\n",
      "step: 4100 \ttraining acc: [0.06333333 0.9        0.90333333 0.91333333 0.91333333 0.91333333]\n",
      "step: 4150 \ttraining acc: [0.07666667 0.82333333 0.89666667 0.91333333 0.90333333 0.92333333]\n",
      "step: 4200 \ttraining acc: [0.04       0.88666667 0.95333333 0.95666667 0.96       0.96      ]\n",
      "step: 4250 \ttraining acc: [0.06       0.9        0.94333333 0.94333333 0.94666667 0.94666667]\n",
      "step: 4300 \ttraining acc: [0.09333333 0.86333333 0.90666667 0.91333333 0.91333333 0.91333333]\n",
      "step: 4350 \ttraining acc: [0.04333333 0.86       0.88333333 0.89666667 0.89666667 0.89666667]\n",
      "step: 4400 \ttraining acc: [0.01666667 0.84666667 0.91666667 0.92333333 0.93333333 0.93666667]\n",
      "step: 4450 \ttraining acc: [0.09666667 0.74       0.83333333 0.86333333 0.86333333 0.86666667]\n",
      "step: 4500 \ttraining acc: [0.07       0.83666667 0.88333333 0.85       0.87       0.87666667]\n",
      "Test acc: [0.05   0.862  0.9023 0.9087 0.914  0.918  0.92   0.921  0.9214 0.9224\n",
      " 0.923 ]\n",
      "step: 4550 \ttraining acc: [0.04       0.83333333 0.9        0.9        0.9        0.9       ]\n",
      "step: 4600 \ttraining acc: [0.00333333 0.85       0.89       0.9        0.89333333 0.92666667]\n",
      "step: 4650 \ttraining acc: [0.00333333 0.89       0.94333333 0.94666667 0.95       0.95333333]\n",
      "step: 4700 \ttraining acc: [0.07       0.85333333 0.91       0.91       0.91       0.91      ]\n",
      "step: 4750 \ttraining acc: [0.04       0.89333333 0.91       0.91333333 0.92666667 0.93      ]\n",
      "step: 4800 \ttraining acc: [0.04333333 0.81666667 0.9        0.9        0.92333333 0.92333333]\n",
      "step: 4850 \ttraining acc: [0.08666667 0.86666667 0.87333333 0.90666667 0.90666667 0.90666667]\n",
      "step: 4900 \ttraining acc: [0.06666667 0.87333333 0.91       0.9        0.91       0.91333333]\n",
      "step: 4950 \ttraining acc: [0.         0.90333333 0.94       0.94       0.94333333 0.94333333]\n",
      "step: 5000 \ttraining acc: [0.05       0.89       0.91333333 0.93333333 0.93333333 0.93333333]\n",
      "Test acc: [0.05072 0.8706  0.9062  0.9126  0.918   0.921   0.9224  0.924   0.9243\n",
      " 0.9253  0.926  ]\n",
      "step: 5050 \ttraining acc: [0.07666667 0.85333333 0.94333333 0.95       0.95333333 0.95333333]\n",
      "step: 5100 \ttraining acc: [0.09333333 0.85333333 0.85666667 0.86666667 0.91       0.91333333]\n",
      "step: 5150 \ttraining acc: [0.05       0.84666667 0.88       0.89666667 0.9        0.90333333]\n",
      "step: 5200 \ttraining acc: [0.00666667 0.86666667 0.92       0.94       0.94333333 0.94      ]\n",
      "step: 5250 \ttraining acc: [0.06666667 0.92666667 0.93333333 0.94       0.95333333 0.95666667]\n",
      "step: 5300 \ttraining acc: [0.05       0.80333333 0.85       0.86333333 0.86333333 0.86333333]\n",
      "step: 5350 \ttraining acc: [0.09       0.94666667 0.95       0.95333333 0.95333333 0.95333333]\n",
      "step: 5400 \ttraining acc: [0.08333333 0.89666667 0.94333333 0.94333333 0.94666667 0.94666667]\n",
      "step: 5450 \ttraining acc: [0.00333333 0.89666667 0.92       0.92333333 0.92333333 0.92      ]\n",
      "step: 5500 \ttraining acc: [0.01333333 0.88       0.93333333 0.94       0.94       0.93666667]\n",
      "Test acc: [0.05145 0.878   0.9126  0.918   0.9224  0.9253  0.927   0.9277  0.9287\n",
      " 0.929   0.9297 ]\n",
      "step: 5550 \ttraining acc: [0.09333333 0.82666667 0.85       0.86333333 0.86666667 0.87333333]\n",
      "step: 5600 \ttraining acc: [0.04333333 0.81333333 0.87666667 0.91666667 0.92       0.92666667]\n",
      "step: 5650 \ttraining acc: [0.03       0.75333333 0.84333333 0.83666667 0.84       0.84      ]\n",
      "step: 5700 \ttraining acc: [0.03666667 0.9        0.93333333 0.93333333 0.93333333 0.93333333]\n",
      "step: 5750 \ttraining acc: [0.05       0.84       0.84666667 0.83666667 0.86333333 0.89333333]\n",
      "step: 5800 \ttraining acc: [0.06333333 0.87666667 0.86333333 0.88666667 0.89       0.89333333]\n",
      "step: 5850 \ttraining acc: [0.04666667 0.85       0.84666667 0.82666667 0.84       0.85333333]\n",
      "step: 5900 \ttraining acc: [0.05333333 0.93333333 0.95666667 0.96       0.96       0.96333333]\n",
      "step: 5950 \ttraining acc: [0.02666667 0.79       0.86666667 0.90666667 0.9        0.9       ]\n",
      "step: 6000 \ttraining acc: [0.         0.84333333 0.83666667 0.83       0.84       0.85666667]\n",
      "Test acc: [0.04977 0.888   0.918   0.923   0.9272  0.929   0.9307  0.9316  0.932\n",
      " 0.9326  0.933  ]\n",
      "step: 6050 \ttraining acc: [0.04       0.84666667 0.9        0.90333333 0.90666667 0.90333333]\n",
      "step: 6100 \ttraining acc: [0.05       0.91       0.93333333 0.93333333 0.93666667 0.94333333]\n",
      "step: 6150 \ttraining acc: [0.08666667 0.94333333 0.96333333 0.96333333 0.96333333 0.96333333]\n",
      "step: 6200 \ttraining acc: [0.1        0.91666667 0.94       0.94       0.94       0.94333333]\n",
      "step: 6250 \ttraining acc: [0.03666667 0.92666667 0.95       0.95       0.95       0.95      ]\n",
      "step: 6300 \ttraining acc: [0.02666667 0.91666667 0.95333333 0.95666667 0.95333333 0.95333333]\n",
      "step: 6350 \ttraining acc: [0.03666667 0.84       0.85666667 0.84       0.86333333 0.85333333]\n",
      "step: 6400 \ttraining acc: [0.03       0.89       0.92333333 0.92333333 0.92666667 0.93      ]\n",
      "step: 6450 \ttraining acc: [0.01666667 0.86       0.90666667 0.91       0.91333333 0.92      ]\n",
      "step: 6500 \ttraining acc: [0.07       0.82       0.86       0.86666667 0.87       0.87666667]\n",
      "Test acc: [0.05035 0.8926  0.921   0.9253  0.929   0.9316  0.933   0.934   0.9346\n",
      " 0.935   0.9355 ]\n",
      "step: 6550 \ttraining acc: [0.02666667 0.87       0.89       0.92333333 0.92666667 0.93333333]\n",
      "step: 6600 \ttraining acc: [0.07       0.89       0.92333333 0.93666667 0.94666667 0.94666667]\n",
      "step: 6650 \ttraining acc: [0.09       0.9        0.93666667 0.94666667 0.95       0.95      ]\n",
      "step: 6700 \ttraining acc: [0.04       0.83666667 0.91333333 0.91666667 0.92       0.92333333]\n",
      "step: 6750 \ttraining acc: [0.05       0.90666667 0.93666667 0.94666667 0.95       0.94666667]\n",
      "step: 6800 \ttraining acc: [0.04333333 0.91333333 0.93333333 0.93333333 0.93666667 0.93666667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 6850 \ttraining acc: [0.05333333 0.83666667 0.92666667 0.93       0.93333333 0.93666667]\n",
      "step: 6900 \ttraining acc: [0.00333333 0.85666667 0.92333333 0.92666667 0.92666667 0.92666667]\n",
      "step: 6950 \ttraining acc: [0.06       0.92666667 0.92666667 0.95666667 0.95666667 0.95666667]\n",
      "step: 7000 \ttraining acc: [0.00666667 0.87666667 0.9        0.91       0.91333333 0.91333333]\n",
      "Test acc: [0.04974 0.895   0.923   0.9277  0.9316  0.9336  0.935   0.936   0.9365\n",
      " 0.937   0.9375 ]\n",
      "step: 7050 \ttraining acc: [0.03       0.91       0.96       0.96       0.96333333 0.97      ]\n",
      "step: 7100 \ttraining acc: [0.07666667 0.88333333 0.91666667 0.92333333 0.92333333 0.92666667]\n",
      "step: 7150 \ttraining acc: [0.06       0.86666667 0.88666667 0.88666667 0.88666667 0.89333333]\n",
      "step: 7200 \ttraining acc: [0.08       0.89333333 0.92666667 0.93333333 0.94       0.94      ]\n",
      "step: 7250 \ttraining acc: [0.05       0.9        0.93333333 0.93666667 0.94333333 0.94      ]\n",
      "step: 7300 \ttraining acc: [0.09666667 0.88       0.91333333 0.91666667 0.91666667 0.91666667]\n",
      "step: 7350 \ttraining acc: [0.01333333 0.94       0.97666667 0.98       0.98333333 0.98333333]\n",
      "step: 7400 \ttraining acc: [0.04       0.92333333 0.94       0.94333333 0.92       0.95333333]\n",
      "step: 7450 \ttraining acc: [0.05666667 0.87       0.93       0.89       0.93333333 0.92333333]\n",
      "step: 7500 \ttraining acc: [0.03333333 0.9        0.92333333 0.93       0.93333333 0.93333333]\n",
      "Test acc: [0.05017 0.8916  0.9185  0.924   0.928   0.9307  0.9326  0.9336  0.9346\n",
      " 0.935   0.9355 ]\n",
      "step: 7550 \ttraining acc: [0.09       0.85333333 0.86666667 0.89333333 0.89       0.88333333]\n",
      "step: 7600 \ttraining acc: [0.04333333 0.95       0.95333333 0.95333333 0.96       0.96      ]\n",
      "step: 7650 \ttraining acc: [0.08666667 0.89666667 0.91       0.92       0.94666667 0.94333333]\n",
      "step: 7700 \ttraining acc: [0.05333333 0.77333333 0.83666667 0.86       0.86666667 0.86666667]\n",
      "step: 7750 \ttraining acc: [0.04666667 0.80333333 0.88       0.84333333 0.89666667 0.89666667]\n",
      "step: 7800 \ttraining acc: [0.08333333 0.87333333 0.91       0.91       0.91       0.91333333]\n",
      "step: 7850 \ttraining acc: [0.05       0.89       0.91333333 0.92333333 0.92333333 0.93      ]\n",
      "step: 7900 \ttraining acc: [0.01       0.91333333 0.96       0.96       0.95666667 0.96      ]\n",
      "step: 7950 \ttraining acc: [0.05333333 0.85666667 0.85333333 0.9        0.89333333 0.89666667]\n",
      "step: 8000 \ttraining acc: [0.02333333 0.94333333 0.95       0.95666667 0.95666667 0.95666667]\n",
      "Test acc: [0.04916 0.8984  0.925   0.929   0.932   0.9346  0.9355  0.9365  0.937\n",
      " 0.9375  0.938  ]\n",
      "step: 8050 \ttraining acc: [0.03       0.79333333 0.87       0.87333333 0.88       0.88333333]\n",
      "step: 8100 \ttraining acc: [0.1        0.85       0.89666667 0.90333333 0.91333333 0.91      ]\n",
      "step: 8150 \ttraining acc: [0.08333333 0.92666667 0.93333333 0.92666667 0.92666667 0.92666667]\n",
      "step: 8200 \ttraining acc: [0.03333333 0.86333333 0.89333333 0.88666667 0.88666667 0.89333333]\n",
      "step: 8250 \ttraining acc: [0.03666667 0.9        0.91666667 0.93666667 0.94       0.94      ]\n",
      "step: 8300 \ttraining acc: [0.00333333 0.88333333 0.91       0.9        0.91333333 0.91666667]\n",
      "step: 8350 \ttraining acc: [0.05333333 0.82666667 0.86       0.85666667 0.88333333 0.91      ]\n",
      "step: 8400 \ttraining acc: [0.06666667 0.86666667 0.90333333 0.91333333 0.92333333 0.91666667]\n",
      "step: 8450 \ttraining acc: [0.08333333 0.88666667 0.96       0.96       0.96333333 0.96333333]\n",
      "step: 8500 \ttraining acc: [0.03666667 0.92       0.93       0.93666667 0.94       0.94      ]\n",
      "Test acc: [0.0498 0.9043 0.928  0.932  0.936  0.9385 0.9395 0.9404 0.941  0.9414\n",
      " 0.942 ]\n",
      "step: 8550 \ttraining acc: [0.06666667 0.89       0.91333333 0.91333333 0.91666667 0.91666667]\n",
      "step: 8600 \ttraining acc: [0.05333333 0.88333333 0.91666667 0.91666667 0.91666667 0.91666667]\n",
      "step: 8650 \ttraining acc: [0.01666667 0.92333333 0.92666667 0.93333333 0.93666667 0.93666667]\n",
      "step: 8700 \ttraining acc: [0.         0.92       0.92666667 0.93666667 0.95       0.94666667]\n",
      "step: 8750 \ttraining acc: [0.07666667 0.88333333 0.86666667 0.89333333 0.92333333 0.92333333]\n",
      "step: 8800 \ttraining acc: [0.06333333 0.90333333 0.92       0.93       0.93       0.93      ]\n",
      "step: 8850 \ttraining acc: [0.08       0.9        0.89666667 0.90333333 0.93333333 0.93333333]\n",
      "step: 8900 \ttraining acc: [0.09333333 0.92333333 0.96666667 0.96666667 0.96666667 0.96666667]\n",
      "step: 8950 \ttraining acc: [0.01       0.89       0.90333333 0.91       0.91       0.91666667]\n",
      "step: 9000 \ttraining acc: [0.06666667 0.89666667 0.90333333 0.88666667 0.90666667 0.91      ]\n",
      "Test acc: [0.04916 0.9053  0.9287  0.9326  0.9365  0.9385  0.94    0.9404  0.9414\n",
      " 0.942   0.9424 ]\n",
      "step: 9050 \ttraining acc: [0.06       0.94       0.96       0.96333333 0.96333333 0.96333333]\n",
      "step: 9100 \ttraining acc: [0.04666667 0.92666667 0.93666667 0.93666667 0.93666667 0.93666667]\n",
      "step: 9150 \ttraining acc: [0.1        0.82666667 0.88666667 0.89333333 0.89       0.89      ]\n",
      "step: 9200 \ttraining acc: [0.02333333 0.94666667 0.95666667 0.95666667 0.95666667 0.95666667]\n",
      "step: 9250 \ttraining acc: [0.09       0.89       0.92333333 0.93333333 0.93333333 0.93333333]\n",
      "step: 9300 \ttraining acc: [0.1        0.96666667 0.97666667 0.97666667 0.97666667 0.98      ]\n",
      "step: 9350 \ttraining acc: [0.04666667 0.91       0.96       0.96       0.96       0.95666667]\n",
      "step: 9400 \ttraining acc: [0.06666667 0.89666667 0.91666667 0.90333333 0.92666667 0.94333333]\n",
      "step: 9450 \ttraining acc: [0.08666667 0.91333333 0.92       0.93333333 0.94333333 0.94666667]\n",
      "step: 9500 \ttraining acc: [0.   0.96 0.96 0.96 0.96 0.96]\n",
      "Test acc: [0.05014 0.9077  0.9307  0.9346  0.9385  0.9404  0.9414  0.9424  0.943\n",
      " 0.9434  0.944  ]\n",
      "step: 9550 \ttraining acc: [0.02       0.91666667 0.93666667 0.93666667 0.93666667 0.93666667]\n",
      "step: 9600 \ttraining acc: [0.09       0.90333333 0.95333333 0.95333333 0.95666667 0.96      ]\n",
      "step: 9650 \ttraining acc: [0.05       0.91333333 0.94333333 0.94       0.94       0.94      ]\n",
      "step: 9700 \ttraining acc: [0.10333333 0.95       0.96666667 0.96666667 0.96666667 0.96666667]\n",
      "step: 9750 \ttraining acc: [0.05       0.89666667 0.92333333 0.92666667 0.92666667 0.93      ]\n",
      "step: 9800 \ttraining acc: [0.01       0.85666667 0.85666667 0.88333333 0.89666667 0.89666667]\n",
      "step: 9850 \ttraining acc: [0.05       0.93666667 0.96333333 0.96666667 0.96666667 0.96666667]\n",
      "step: 9900 \ttraining acc: [0.         0.93666667 0.96333333 0.96333333 0.96333333 0.96333333]\n",
      "step: 9950 \ttraining acc: [0.02333333 0.89       0.89666667 0.89333333 0.89333333 0.89333333]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(222)\n",
    "torch.cuda.manual_seed_all(222)\n",
    "np.random.seed(222)\n",
    "\n",
    "\"\"\"\n",
    "maml_config = [\n",
    "    ('conv2d', [64, 1, 3, 3, 1, 1]),\n",
    "    ('bn', [64]),\n",
    "    ('relu', [True]),  #  max_pool2d\n",
    "    ('max_pool2d', [2, 2, 0]),\n",
    "    ('conv2d', [64, 64, 3, 3, 1, 1]),\n",
    "    ('bn', [64]),\n",
    "    ('relu', [True]),\n",
    "    ('max_pool2d', [2, 2, 0]),\n",
    "    ('conv2d', [64, 64, 3, 3, 1, 1]),\n",
    "    ('bn', [64]),\n",
    "    ('relu', [True]),\n",
    "    ('max_pool2d', [2, 2, 0]),\n",
    "    ('conv2d', [64, 64, 3, 3, 1, 1]),\n",
    "    ('bn', [64]),\n",
    "    ('relu', [True]),\n",
    "    ('max_pool2d', [2, 2, 0]),\n",
    "    ('flatten', []),\n",
    "    ('linear', [args.n_way, 64])\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "maml_config = [\n",
    "        ('conv2d', [64, 1, 3, 3, 2, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [64]),\n",
    "        ('conv2d', [64, 64, 3, 3, 2, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [64]),\n",
    "        ('conv2d', [64, 64, 3, 3, 2, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [64]),\n",
    "        ('conv2d', [64, 64, 2, 2, 1, 0]),\n",
    "        ('relu', [True]),\n",
    "        ('bn', [64]),\n",
    "        ('flatten', []),\n",
    "        ('linear', [args.n_way, 64])\n",
    "    ]\n",
    "\n",
    "device = torch.device('cpu')\n",
    "maml = Meta(args, maml_config).to(device)\n",
    "\n",
    "tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "print(maml)\n",
    "print('Total trainable tensors:', num)\n",
    "\n",
    "for step in range(args.epoch):\n",
    "    data_shot, label_shot, data_query, label_query = g.get_shot_query(config, device)\n",
    "    x_spt = data_shot[None, ...]\n",
    "    y_spt = label_shot[None, ...]\n",
    "    x_qry = data_query[None, ...]\n",
    "    y_qry = label_query[None, ...]\n",
    "\n",
    "    # set traning=True to update running_mean, running_variance, bn_weights, bn_bias\n",
    "    accs = maml(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "    if step % 50 == 0:\n",
    "        print('step:', step, '\\ttraining acc:', accs)\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        accs = []\n",
    "        for _ in range(1000//args.task_num):\n",
    "            data_shot, label_shot, data_query, label_query = g.get_shot_query(config, device)\n",
    "            x_spt = data_shot\n",
    "            y_spt = label_shot\n",
    "            x_qry = data_query\n",
    "            y_qry = label_query\n",
    "\n",
    "            # split to single task each time\n",
    "            test_acc = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "            accs.append( test_acc )\n",
    "\n",
    "        # [b, update_step+1]\n",
    "        print('Test acc:', np.array(accs).mean(axis=0).astype(np.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maml.eval()\n",
    "accs = []\n",
    "for _ in range(1000//args.task_num):\n",
    "    data_shot, label_shot, data_query, label_query = g.get_shot_query(config, device, validation=True)\n",
    "    x_spt = data_shot\n",
    "    y_spt = label_shot\n",
    "    x_qry = data_query\n",
    "    y_qry = label_query\n",
    "\n",
    "    # split to single task each time\n",
    "    test_acc = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "    accs.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9402900000000037, 0.07915065171346782)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs, axis=0)[-1], 100 * np.std(accs,  axis=0)[-1]/np.sqrt(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "alphabet_g = alphabet_generator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "for _ in range(1000//args.task_num):\n",
    "    data_shot, label_shot, data_query, label_query = alphabet_g.get_shot_query(config, device)\n",
    "    x_spt = data_shot\n",
    "    y_spt = label_shot\n",
    "    x_qry = data_query\n",
    "    y_qry = label_query\n",
    "\n",
    "    # split to single task each time\n",
    "    test_acc = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "    accs.append( test_acc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8990512820512805, 0.282552501440842)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs, axis=0)[-1], 100 * np.std(accs,  axis=0)[-1]/np.sqrt(1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch38",
   "language": "python",
   "name": "pytorch38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
